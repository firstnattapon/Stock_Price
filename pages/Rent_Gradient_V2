# """
# Geoapify CBD x Longdo GIS + Network Analysis
# ==============================================
# Refactored: Modular Monolith Architecture
# - Section 1: Constants & Configuration
# - Section 2: State Manager (Centralized Session State)
# - Section 3: Pure Functions (No st.* ‚Äî testable, cacheable)
# - Section 4: Cached Wrappers (@st.cache_data)
# - Section 5: UI Components (st.* allowed)
# - Section 6: Business Logic Orchestrators
# - Section 7: Main Execution
# """

# import streamlit as st
# import folium
# from streamlit_folium import st_folium
# import requests
# from shapely.geometry import shape, mapping
# from shapely.ops import unary_union
# from shapely import wkt
# import json
# import networkx as nx
# import osmnx as ox
# import matplotlib.cm as cm
# import matplotlib.colors as colors
# from typing import List, Dict, Any, Optional, Tuple
# import time
# import hashlib
# import pickle
# import os
# from pathlib import Path
# import zipfile
# import io
# from math import radians, sin, cos, sqrt, atan2


# # ============================================================================
# # SECTION 1: CONSTANTS & CONFIGURATION
# # ============================================================================

# PAGE_CONFIG: Dict[str, Any] = {
#     "page_title": "Geoapify CBD x Longdo GIS + Network Analysis",
#     "page_icon": "üåç",
#     "layout": "wide",
# }

# DEFAULT_CONFIG: Dict[str, Any] = {
#     "JSON_URL": (
#         "https://raw.githubusercontent.com/firstnattapon/Stock_Price/"
#         "refs/heads/main/Geoapify_Map/geoapify_cbd_project.json"
#     ),
#     "LAT": 20.219443,
#     "LON": 100.403630,
#     "GEOAPIFY_KEY": "4eefdfb0b0d349e595595b9c03a69e3d",
#     "LONGDO_KEY": "0a999afb0da60c5c45d010e9c171ffc8",
# }

# LONGDO_WMS_URL: str = (
#     f"https://ms.longdo.com/mapproxy/service?key={DEFAULT_CONFIG['LONGDO_KEY']}"
# )

# # --- Visual Assets ---
# MARKER_COLORS: List[str] = [
#     "red", "blue", "green", "purple", "orange", "black", "pink", "cadetblue"
# ]
# HEX_COLORS: List[str] = [
#     "#D63E2A", "#38AADD", "#72B026", "#D252B9",
#     "#F69730", "#333333", "#FF91EA", "#436978",
# ]

# MAP_STYLES: Dict[str, Dict[str, Optional[str]]] = {
#     "Esri Light Gray (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡∏ú‡∏±‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á)": {
#         "tiles": (
#             "https://server.arcgisonline.com/ArcGIS/rest/services/"
#             "Canvas/World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}"
#         ),
#         "attr": "Tiles &copy; Esri",
#     },
#     "Google Maps (‡∏ú‡∏™‡∏°/Hybrid)": {
#         "tiles": "https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}",
#         "attr": "Google Maps",
#     },
#     "OpenStreetMap (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)": {
#         "tiles": "OpenStreetMap",
#         "attr": None,
#     },
#     "Esri Satellite (‡∏î‡∏≤‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏°‡∏ä‡∏±‡∏î)": {
#         "tiles": (
#             "https://server.arcgisonline.com/ArcGIS/rest/services/"
#             "World_Imagery/MapServer/tile/{z}/{y}/{x}"
#         ),
#         "attr": "Tiles &copy; Esri",
#     },
# }

# TRAVEL_MODE_NAMES: Dict[str, str] = {
#     "drive": "üöó ‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ",
#     "walk": "üö∂ ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤",
#     "bicycle": "üö≤ ‡∏õ‡∏±‡πà‡∏ô‡∏à‡∏±‡∏Å‡∏£‡∏¢‡∏≤‡∏ô",
#     "transit": "üöå ‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞",
# }

# TIME_OPTIONS: List[int] = [5, 10, 15, 20, 30, 45, 60]

# # Cache Directory (disk-based OSM graph storage)
# CACHE_DIR: Path = Path("./cache")
# CACHE_DIR.mkdir(exist_ok=True)

# # Network Analysis Configuration
# NETWORK_CONFIG: Dict[str, Any] = {
#     "min_closeness_threshold": 0.0,
#     "edge_weight_base": 2,
#     "edge_weight_multiplier": 4,
#     "cache_ttl_seconds": 3600,
#     "click_debounce_seconds": 0.5,
#     "click_distance_threshold_meters": 10,
#     "large_graph_threshold": 2000,
# }

# # Timeout constants (seconds)
# TIMEOUT_API: int = 15
# TIMEOUT_INIT: int = 3
# TIMEOUT_GITHUB_LIST: int = 10
# TIMEOUT_GITHUB_DOWNLOAD: int = 60

# # Map Geoapify travel_mode -> OSMnx network_type
# TRAVEL_MODE_TO_NETWORK_TYPE: Dict[str, str] = {
#     "drive": "drive",
#     "walk": "walk",
#     "bicycle": "bike",
#     "transit": "drive",  # OSMnx has no transit; fallback to drive
# }

# # Keys to persist in config file
# SESSION_KEYS_TO_SAVE: List[str] = [
#     "api_key", "map_style_name", "travel_mode", "time_intervals",
#     "show_dol", "show_cityplan", "cityplan_opacity", "show_population",
#     "show_traffic", "colors", "show_betweenness", "show_closeness",
# ]

# # GitHub Cache Repository Configuration
# GITHUB_CACHE_CONFIG: Dict[str, str] = {
#     "api_url": (
#         "https://api.github.com/repos/firstnattapon/Stock_Price/"
#         "contents/Geoapify_Map"
#     ),
#     "raw_base_url": (
#         "https://raw.githubusercontent.com/firstnattapon/"
#         "Stock_Price/main/Geoapify_Map"
#     ),
# }


# # ============================================================================
# # SECTION 2: STATE MANAGER (Centralized Session State)
# # ============================================================================

# class StateManager:
#     """
#     Centralized session-state management.

#     All reads / writes to ``st.session_state`` go through this class
#     so that key names are defined once and typos are caught at the
#     class level instead of buried in UI code.
#     """

#     # ---- Key constants (single source of truth) ----
#     K_MARKERS: str = "markers"
#     K_ISOCHRONE: str = "isochrone_data"
#     K_INTERSECTION: str = "intersection_data"
#     K_NETWORK: str = "network_data"
#     K_LAST_CLICK: str = "last_processed_click"
#     K_COLORS: str = "colors"
#     K_API_KEY: str = "api_key"
#     K_MAP_STYLE: str = "map_style_name"
#     K_TRAVEL_MODE: str = "travel_mode"
#     K_TIME_INTERVALS: str = "time_intervals"
#     K_SHOW_DOL: str = "show_dol"
#     K_SHOW_CITYPLAN: str = "show_cityplan"
#     K_CITYPLAN_OPACITY: str = "cityplan_opacity"
#     K_SHOW_POPULATION: str = "show_population"
#     K_SHOW_TRAFFIC: str = "show_traffic"
#     K_SHOW_BETWEENNESS: str = "show_betweenness"
#     K_SHOW_CLOSENESS: str = "show_closeness"

#     # ---- Default values ----
#     _DEFAULTS: Dict[str, Any] = {
#         K_MARKERS: None,  # Will be set from remote JSON or fallback
#         K_ISOCHRONE: None,
#         K_INTERSECTION: None,
#         K_NETWORK: None,
#         K_LAST_CLICK: None,
#         K_COLORS: {
#             "step1": "#2A9D8F",
#             "step2": "#E9C46A",
#             "step3": "#F4A261",
#             "step4": "#D62828",
#         },
#         K_API_KEY: DEFAULT_CONFIG["GEOAPIFY_KEY"],
#         K_MAP_STYLE: "Esri Light Gray (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡∏ú‡∏±‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á)",
#         K_TRAVEL_MODE: "drive",
#         K_TIME_INTERVALS: [5],
#         K_SHOW_DOL: False,
#         K_SHOW_CITYPLAN: False,
#         K_CITYPLAN_OPACITY: 0.7,
#         K_SHOW_POPULATION: False,
#         K_SHOW_TRAFFIC: False,
#         K_SHOW_BETWEENNESS: False,
#         K_SHOW_CLOSENESS: False,
#     }

#     _DEFAULT_MARKER: Dict[str, Any] = {
#         "lat": DEFAULT_CONFIG["LAT"],
#         "lng": DEFAULT_CONFIG["LON"],
#         "active": True,
#     }

#     # ------------------------------------------------------------------ init
#     @classmethod
#     def initialize(cls) -> None:
#         """Initialize all session-state variables with defaults.

#         On first load, attempts to pull saved state from a remote JSON.
#         Subsequent reruns are no-ops for keys that already exist.
#         """
#         first_run = cls.K_MARKERS not in st.session_state

#         # Resolve starting defaults (possibly from remote)
#         defaults = dict(cls._DEFAULTS)
#         if first_run:
#             defaults[cls.K_MARKERS] = cls._load_remote_defaults(defaults)

#         # Fallback marker list
#         if defaults[cls.K_MARKERS] is None:
#             defaults[cls.K_MARKERS] = [dict(cls._DEFAULT_MARKER)]

#         # Apply defaults using setdefault (idempotent)
#         for key, value in defaults.items():
#             st.session_state.setdefault(key, value)

#         # Ensure every marker dict has an 'active' key
#         for m in st.session_state[cls.K_MARKERS]:
#             m.setdefault("active", True)

#     @staticmethod
#     def _load_remote_defaults(defaults: Dict[str, Any]) -> Optional[List[Dict]]:
#         """Attempt to load initial state from the remote JSON URL."""
#         try:
#             resp = requests.get(
#                 DEFAULT_CONFIG["JSON_URL"], timeout=TIMEOUT_INIT
#             )
#             if resp.status_code == 200:
#                 data: Dict[str, Any] = resp.json()
#                 # Merge remote settings into defaults
#                 for k in defaults:
#                     if k in data:
#                         defaults[k] = data[k]
#                 return data.get("markers")
#         except Exception:
#             pass
#         return None

#     # ------------------------------------------------------------- accessors
#     @classmethod
#     def get_markers(cls) -> List[Dict[str, Any]]:
#         return st.session_state[cls.K_MARKERS]

#     @classmethod
#     def get_active_markers(cls) -> List[Tuple[int, Dict[str, Any]]]:
#         """Return list of (original_index, marker_dict) for active markers."""
#         return [
#             (i, m)
#             for i, m in enumerate(st.session_state[cls.K_MARKERS])
#             if m.get("active", True)
#         ]

#     @classmethod
#     def get_isochrone_data(cls) -> Optional[Dict[str, Any]]:
#         return st.session_state[cls.K_ISOCHRONE]

#     @classmethod
#     def get_intersection_data(cls) -> Optional[Dict[str, Any]]:
#         return st.session_state[cls.K_INTERSECTION]

#     @classmethod
#     def get_network_data(cls) -> Optional[Dict[str, Any]]:
#         return st.session_state[cls.K_NETWORK]

#     @classmethod
#     def get_colors(cls) -> Dict[str, str]:
#         return st.session_state[cls.K_COLORS]

#     @classmethod
#     def get_api_key(cls) -> str:
#         return st.session_state[cls.K_API_KEY]

#     @classmethod
#     def get_travel_mode(cls) -> str:
#         return st.session_state[cls.K_TRAVEL_MODE]

#     @classmethod
#     def get_time_intervals(cls) -> List[int]:
#         return st.session_state[cls.K_TIME_INTERVALS]

#     @classmethod
#     def get_map_style_name(cls) -> str:
#         return st.session_state[cls.K_MAP_STYLE]

#     # -------------------------------------------------------------- mutators
#     @classmethod
#     def set_isochrone_data(cls, data: Optional[Dict[str, Any]]) -> None:
#         st.session_state[cls.K_ISOCHRONE] = data

#     @classmethod
#     def set_intersection_data(cls, data: Optional[Dict[str, Any]]) -> None:
#         st.session_state[cls.K_INTERSECTION] = data

#     @classmethod
#     def set_network_data(cls, data: Optional[Dict[str, Any]]) -> None:
#         st.session_state[cls.K_NETWORK] = data

#     @classmethod
#     def add_marker(cls, lat: float, lng: float) -> None:
#         st.session_state[cls.K_MARKERS].append(
#             {"lat": lat, "lng": lng, "active": True}
#         )

#     @classmethod
#     def remove_marker(cls, index: int) -> None:
#         markers = st.session_state[cls.K_MARKERS]
#         if 0 <= index < len(markers):
#             markers.pop(index)

#     @classmethod
#     def pop_last_marker(cls) -> None:
#         markers = st.session_state[cls.K_MARKERS]
#         if markers:
#             markers.pop()

#     @classmethod
#     def set_marker_active(cls, index: int, active: bool) -> None:
#         st.session_state[cls.K_MARKERS][index]["active"] = active

#     @classmethod
#     def record_click(cls, lat: float, lon: float) -> None:
#         st.session_state[cls.K_LAST_CLICK] = {
#             "timestamp": time.time(),
#             "lat": lat,
#             "lon": lon,
#         }

#     @classmethod
#     def get_last_click(cls) -> Optional[Dict[str, Any]]:
#         return st.session_state.get(cls.K_LAST_CLICK)

#     # ------------------------------------------------------- cache clearing
#     @classmethod
#     def clear_results(cls, layers: Optional[List[str]] = None) -> None:
#         """
#         Smart cache invalidation ‚Äî clear only specified layers.

#         Args:
#             layers: ``['isochrone', 'intersection', 'network']``.
#                     ``None`` clears all.
#         """
#         if layers is None:
#             layers = ["isochrone", "intersection", "network"]

#         if "isochrone" in layers:
#             st.session_state[cls.K_ISOCHRONE] = None
#         if "intersection" in layers:
#             st.session_state[cls.K_INTERSECTION] = None
#         if "network" in layers:
#             st.session_state[cls.K_NETWORK] = None

#     @classmethod
#     def reset(cls) -> None:
#         """Reset to factory defaults."""
#         st.session_state[cls.K_MARKERS] = [dict(cls._DEFAULT_MARKER)]
#         st.session_state[cls.K_LAST_CLICK] = None
#         cls.clear_results()

#     @classmethod
#     def import_config(cls, data: Dict[str, Any]) -> None:
#         """Import settings from an uploaded config dict."""
#         if "markers" in data:
#             st.session_state[cls.K_MARKERS] = data["markers"]
#         settings = data.get("settings", {})
#         for k, v in settings.items():
#             if k in SESSION_KEYS_TO_SAVE:
#                 st.session_state[k] = v
#         cls.clear_results()

#     @classmethod
#     def export_config(cls) -> str:
#         """Export current config as a JSON string."""
#         return json.dumps(
#             {
#                 "markers": st.session_state[cls.K_MARKERS],
#                 "settings": {
#                     k: st.session_state[k]
#                     for k in SESSION_KEYS_TO_SAVE
#                     if k in st.session_state
#                 },
#             },
#             indent=2,
#             ensure_ascii=False,
#         )


# # ============================================================================
# # SECTION 3: PURE FUNCTIONS (No st.* ‚Äî testable, cacheable)
# # ============================================================================

# # --------------------------------------------------------------------- Geometry
# def get_fill_color(minutes: float, colors_config: Dict[str, str]) -> str:
#     """Determine polygon fill colour based on travel-time bucket."""
#     if minutes <= 10:
#         return colors_config["step1"]
#     if minutes <= 20:
#         return colors_config["step2"]
#     if minutes <= 30:
#         return colors_config["step3"]
#     return colors_config["step4"]


# def get_border_color(original_marker_idx: Optional[int]) -> str:
#     """Determine border colour from marker index."""
#     if original_marker_idx is None:
#         return "#3388ff"
#     return HEX_COLORS[original_marker_idx % len(HEX_COLORS)]


# def calculate_distance_meters(
#     lat1: float, lon1: float, lat2: float, lon2: float
# ) -> float:
#     """Haversine distance in metres."""
#     R = 6371000.0
#     lat1_rad, lon1_rad = radians(lat1), radians(lon1)
#     lat2_rad, lon2_rad = radians(lat2), radians(lon2)
#     dlat = lat2_rad - lat1_rad
#     dlon = lon2_rad - lon1_rad
#     a = sin(dlat / 2) ** 2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2) ** 2
#     c = 2 * atan2(sqrt(a), sqrt(1 - a))
#     return R * c


# def should_add_marker(
#     new_lat: float,
#     new_lon: float,
#     last_click: Optional[Dict[str, Any]],
# ) -> bool:
#     """
#     Debounce logic ‚Äî returns ``True`` when a new marker should be added.

#     Pure function: caller supplies ``last_click`` instead of reading
#     ``st.session_state`` directly.
#     """
#     if last_click is None:
#         return True

#     time_diff = time.time() - last_click["timestamp"]
#     if time_diff < NETWORK_CONFIG["click_debounce_seconds"]:
#         return False

#     distance = calculate_distance_meters(
#         last_click["lat"], last_click["lon"], new_lat, new_lon
#     )
#     if distance < NETWORK_CONFIG["click_distance_threshold_meters"]:
#         return False

#     return True


# def calculate_intersection(
#     features: List[Dict[str, Any]], num_active_markers: int
# ) -> Optional[Dict[str, Any]]:
#     """Calculate the geometric intersection (CBD) of isochrones."""
#     if num_active_markers < 2:
#         return None

#     polys_per_active_idx: Dict[int, Any] = {}
#     for feat in features:
#         active_idx: int = feat["properties"]["active_index"]
#         geom = shape(feat["geometry"])
#         if active_idx in polys_per_active_idx:
#             polys_per_active_idx[active_idx] = polys_per_active_idx[active_idx].union(geom)
#         else:
#             polys_per_active_idx[active_idx] = geom

#     if len(polys_per_active_idx) < num_active_markers:
#         return None

#     active_indices = sorted(polys_per_active_idx.keys())
#     try:
#         intersection_poly = polys_per_active_idx[active_indices[0]]
#         for idx in active_indices[1:]:
#             intersection_poly = intersection_poly.intersection(polys_per_active_idx[idx])
#             if intersection_poly.is_empty:
#                 return None
#         if intersection_poly.is_empty:
#             return None
#         return mapping(intersection_poly)
#     except Exception:
#         return None


# # ------------------------------------------------------------------ API calls
# def safe_fetch_isochrone(
#     api_key: str,
#     travel_mode: str,
#     ranges_str: str,
#     marker_lat: float,
#     marker_lon: float,
# ) -> Tuple[Optional[List[Dict[str, Any]]], Optional[str]]:
#     """
#     Fetch isochrone data from Geoapify with full error handling.

#     Returns:
#         ``(features_list, None)`` on success,
#         ``(None, error_message)`` on failure.
#     """
#     url = "https://api.geoapify.com/v1/isoline"
#     params: Dict[str, Any] = {
#         "lat": marker_lat,
#         "lon": marker_lon,
#         "type": "time",
#         "mode": travel_mode,
#         "range": ranges_str,
#         "apiKey": api_key,
#     }

#     try:
#         response = requests.get(url, params=params, timeout=TIMEOUT_API)

#         if response.status_code == 200:
#             data = response.json()
#             features = data.get("features")
#             if features is None:
#                 return None, "API response missing 'features' data"
#             return features, None
#         elif response.status_code == 401:
#             return None, "‚ùå Invalid API Key ‚Äì Please check your Geoapify API key"
#         elif response.status_code == 403:
#             return None, "‚ùå API Key Forbidden ‚Äì Check your account permissions"
#         elif response.status_code == 429:
#             return None, "‚ö†Ô∏è Rate Limit Exceeded ‚Äì Please wait before retrying"
#         else:
#             return None, f"API Error (Status {response.status_code}): {response.text[:100]}"

#     except requests.Timeout:
#         return None, "‚è±Ô∏è Request Timeout ‚Äì API took too long to respond"
#     except requests.ConnectionError:
#         return None, "üåê Connection Error ‚Äì Check your internet connection"
#     except requests.RequestException as e:
#         return None, f"Network Error: {str(e)}"
#     except json.JSONDecodeError:
#         return None, "Invalid JSON response from API"
#     except Exception as e:
#         return None, f"Unexpected Error: {str(e)}"


# # -------------------------------------------------------------- Disk caching
# def get_cache_key(polygon_wkt_str: str, network_type: str) -> str:
#     """Generate a stable cache key from polygon bounds + network type."""
#     polygon = wkt.loads(polygon_wkt_str)
#     bounds = polygon.bounds  # (minx, miny, maxx, maxy)
#     rounded_bounds = tuple(round(b, 3) for b in bounds)
#     key_str = f"{rounded_bounds}_{network_type}"
#     return hashlib.md5(key_str.encode()).hexdigest()


# def load_graph_from_cache(cache_key: str) -> Optional[nx.MultiDiGraph]:
#     """Load a cached OSM graph from disk."""
#     cache_file = CACHE_DIR / f"osm_graph_{cache_key}.pkl"
#     if cache_file.exists():
#         try:
#             with open(cache_file, "rb") as f:
#                 return pickle.load(f)
#         except Exception:
#             return None
#     return None


# def save_graph_to_cache(cache_key: str, graph: nx.MultiDiGraph) -> None:
#     """Persist an OSM graph to disk."""
#     cache_file = CACHE_DIR / f"osm_graph_{cache_key}.pkl"
#     try:
#         with open(cache_file, "wb") as f:
#             pickle.dump(graph, f, protocol=pickle.HIGHEST_PROTOCOL)
#     except Exception:
#         pass  # Caching is best-effort


# def get_cache_stats() -> Dict[str, Any]:
#     """Return ``{count, size_mb}`` for the disk cache."""
#     if not CACHE_DIR.exists():
#         return {"count": 0, "size_mb": 0.0}
#     cache_files = list(CACHE_DIR.glob("osm_graph_*.pkl"))
#     total_size = sum(f.stat().st_size for f in cache_files)
#     return {"count": len(cache_files), "size_mb": total_size / (1024 * 1024)}


# def clear_disk_cache() -> None:
#     """Delete all cached OSM graphs."""
#     if CACHE_DIR.exists():
#         for cache_file in CACHE_DIR.glob("osm_graph_*.pkl"):
#             try:
#                 cache_file.unlink()
#             except Exception:
#                 pass


# def export_cache_as_zip() -> Optional[bytes]:
#     """Create an in-memory ZIP of all cached graphs."""
#     if not CACHE_DIR.exists():
#         return None
#     cache_files = list(CACHE_DIR.glob("osm_graph_*.pkl"))
#     if not cache_files:
#         return None

#     zip_buffer = io.BytesIO()
#     with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
#         for cache_file in cache_files:
#             zf.write(cache_file, cache_file.name)
#     zip_buffer.seek(0)
#     return zip_buffer.getvalue()


# def import_cache_from_zip(zip_bytes: bytes) -> Dict[str, Any]:
#     """Import cache entries from a ZIP archive."""
#     result: Dict[str, Any] = {
#         "success": False,
#         "imported": 0,
#         "skipped": 0,
#         "errors": [],
#     }

#     try:
#         CACHE_DIR.mkdir(exist_ok=True)
#         zip_buffer = io.BytesIO(zip_bytes)
#         with zipfile.ZipFile(zip_buffer, "r") as zf:
#             for file_info in zf.infolist():
#                 name = file_info.filename
#                 if not name.startswith("osm_graph_") or not name.endswith(".pkl"):
#                     result["errors"].append(f"Skipped invalid file: {name}")
#                     continue

#                 target_path = CACHE_DIR / name
#                 if target_path.exists():
#                     result["skipped"] += 1
#                     continue

#                 try:
#                     data = zf.read(name)
#                     # Validate pickle
#                     pickle.load(io.BytesIO(data))
#                     with open(target_path, "wb") as f:
#                         f.write(data)
#                     result["imported"] += 1
#                 except Exception as e:
#                     result["errors"].append(f"Failed to import {name}: {str(e)}")

#         result["success"] = result["imported"] > 0 or result["skipped"] > 0
#     except zipfile.BadZipFile:
#         result["errors"].append("Invalid ZIP file format")
#     except Exception as e:
#         result["errors"].append(f"Import failed: {str(e)}")

#     return result


# # -------------------------------------------------------- GitHub cache helpers
# def _fetch_github_cache_list_impl() -> List[Dict[str, Any]]:
#     """(Pure) Fetch list of ``*_cache.zip`` files from the GitHub repo."""
#     try:
#         response = requests.get(
#             GITHUB_CACHE_CONFIG["api_url"], timeout=TIMEOUT_GITHUB_LIST
#         )
#         if response.status_code != 200:
#             return []
#         files = response.json()
#         cache_files: List[Dict[str, Any]] = []
#         for f in files:
#             if isinstance(f, dict) and f.get("name", "").endswith("_cache.zip"):
#                 cache_files.append(
#                     {
#                         "name": f["name"],
#                         "download_url": f.get("download_url", ""),
#                         "size_kb": f.get("size", 0) // 1024,
#                     }
#                 )
#         return cache_files
#     except Exception:
#         return []


# def download_github_cache(download_url: str) -> Tuple[Optional[bytes], Optional[str]]:
#     """Download a cache ZIP from GitHub. Returns ``(bytes, error_msg)``."""
#     try:
#         response = requests.get(download_url, timeout=TIMEOUT_GITHUB_DOWNLOAD)
#         if response.status_code == 200:
#             return response.content, None
#         return None, f"‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (HTTP {response.status_code})"
#     except requests.Timeout:
#         return None, "‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà"
#     except Exception as e:
#         return None, f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"


# # ------------------------------------------------ Network analysis (pure logic)
# def _fetch_osm_graph(
#     polygon_wkt_str: str, network_type: str
# ) -> Tuple[Optional[nx.MultiDiGraph], bool, Optional[str]]:
#     """
#     Fetch an OSM graph for a polygon, with disk-cache lookup.

#     Returns:
#         ``(graph, was_cached, error_message)``
#     """
#     try:
#         cache_key = get_cache_key(polygon_wkt_str, network_type)
#         polygon_geom = wkt.loads(polygon_wkt_str)

#         G = load_graph_from_cache(cache_key)
#         if G is not None:
#             return G, True, None

#         G = ox.graph_from_polygon(
#             polygon_geom, network_type=network_type, truncate_by_edge=True
#         )
#         save_graph_to_cache(cache_key, G)
#         return G, False, None

#     except ValueError as e:
#         return None, False, f"Invalid geometry: {str(e)}"
#     except ox._errors.InsufficientResponseError:
#         return None, False, (
#             "No OSM data available for this area. "
#             "Try a different location or larger region."
#         )
#     except Exception as e:
#         return None, False, f"Failed to fetch OSM graph: {str(e)}"


# def _compute_centrality_impl(
#     polygon_wkt_str: str, network_type: str = "drive"
# ) -> Dict[str, Any]:
#     """
#     **Pure** centrality computation ‚Äî no Streamlit calls.

#     Returns a result dict with keys:
#     ``edges``, ``nodes``, ``top_node``, ``stats``  ‚Äî or  ``error``.
#     """
#     G, was_cached, error = _fetch_osm_graph(polygon_wkt_str, network_type)
#     if error:
#         return {"error": error}

#     if G is None or len(G.nodes) < 2:
#         return {
#             "error": (
#                 "Not enough nodes found in the area. "
#                 "Try a larger region or check if OSM data is available."
#             )
#         }

#     node_count = len(G.nodes)
#     is_large_graph = node_count > NETWORK_CONFIG["large_graph_threshold"]

#     # Closeness centrality
#     closeness_cent: Dict[Any, float] = nx.closeness_centrality(G)
#     max_close = max(closeness_cent.values()) if closeness_cent else 1.0

#     # Betweenness centrality (on undirected projection)
#     G_undir = G.to_undirected()
#     betweenness_cent: Dict[Any, float] = nx.edge_betweenness_centrality(
#         G_undir, weight="length"
#     )
#     max_bet = max(betweenness_cent.values()) if betweenness_cent else 1.0

#     # Colour-map for betweenness
#     try:
#         cmap_bet = cm.colormaps["plasma"]
#     except AttributeError:
#         cmap_bet = cm.get_cmap("plasma")  # older matplotlib

#     # ---- Build edge GeoJSON features ----
#     edges_geojson: List[Dict[str, Any]] = []
#     for u, v, _k, data in G.edges(keys=True, data=True):
#         score = betweenness_cent.get(tuple(sorted((u, v))), 0.0)
#         norm_score = score / max_bet if max_bet > 0 else 0.0

#         if "geometry" in data:
#             geom = mapping(data["geometry"])
#         else:
#             geom = {
#                 "type": "LineString",
#                 "coordinates": [
#                     [G.nodes[u]["x"], G.nodes[u]["y"]],
#                     [G.nodes[v]["x"], G.nodes[v]["y"]],
#                 ],
#             }

#         edges_geojson.append(
#             {
#                 "type": "Feature",
#                 "geometry": geom,
#                 "properties": {
#                     "type": "road",
#                     "betweenness": norm_score,
#                     "color": colors.to_hex(cmap_bet(norm_score)),
#                     "stroke_weight": (
#                         NETWORK_CONFIG["edge_weight_base"]
#                         + norm_score * NETWORK_CONFIG["edge_weight_multiplier"]
#                     ),
#                 },
#             }
#         )

#     # ---- Build node GeoJSON features ----
#     nodes_geojson: List[Dict[str, Any]] = []
#     top_node_data: Dict[str, Any] = {"score": -1.0, "lat": 0.0, "lon": 0.0}

#     for node, data in G.nodes(data=True):
#         score = closeness_cent.get(node, 0.0)
#         norm_score = score / max_close if max_close > 0 else 0.0

#         if score > top_node_data["score"]:
#             top_node_data = {"lat": data["y"], "lon": data["x"], "score": score}

#         if norm_score > NETWORK_CONFIG["min_closeness_threshold"]:
#             nodes_geojson.append(
#                 {
#                     "type": "Feature",
#                     "geometry": {
#                         "type": "Point",
#                         "coordinates": [data["x"], data["y"]],
#                     },
#                     "properties": {
#                         "type": "intersection",
#                         "closeness": norm_score,
#                         "color": "#000000",
#                         "radius": 2 + norm_score * 6,
#                     },
#                 }
#             )

#     return {
#         "edges": {"type": "FeatureCollection", "features": edges_geojson},
#         "nodes": {"type": "FeatureCollection", "features": nodes_geojson},
#         "top_node": top_node_data if top_node_data["score"] != -1.0 else None,
#         "stats": {
#             "nodes_count": len(G.nodes),
#             "edges_count": len(G.edges),
#             "used_approximation": is_large_graph,
#             "was_cached": was_cached,
#         },
#     }


# # ============================================================================
# # SECTION 4: CACHED WRAPPERS (@st.cache_data)
# # ============================================================================

# @st.cache_data(show_spinner=False, ttl=NETWORK_CONFIG["cache_ttl_seconds"])
# def fetch_api_data_cached(
#     api_key: str,
#     travel_mode: str,
#     ranges_str: str,
#     marker_lat: float,
#     marker_lon: float,
# ) -> Tuple[Optional[List[Dict[str, Any]]], Optional[str]]:
#     """Streamlit-cached wrapper around the isochrone API call."""
#     return safe_fetch_isochrone(api_key, travel_mode, ranges_str, marker_lat, marker_lon)


# @st.cache_data(show_spinner=False, ttl=NETWORK_CONFIG["cache_ttl_seconds"])
# def union_all_polygons_cached(features_json_str: str) -> str:
#     """
#     Union all polygon features ‚Üí WKT string.

#     Takes a JSON **string** so that the argument is hashable for caching.
#     """
#     features: List[Dict[str, Any]] = json.loads(features_json_str)
#     polys = [shape(f["geometry"]) for f in features]
#     if not polys:
#         return ""
#     combined = unary_union(polys)
#     return combined.wkt


# @st.cache_data(show_spinner=False, ttl=NETWORK_CONFIG["cache_ttl_seconds"])
# def compute_centrality_cached(
#     polygon_wkt_str: str, network_type: str = "drive"
# ) -> Dict[str, Any]:
#     """Streamlit-cached wrapper for the pure centrality computation."""
#     return _compute_centrality_impl(polygon_wkt_str, network_type)


# @st.cache_data(ttl=3600, show_spinner=False)
# def fetch_github_cache_list_cached() -> List[Dict[str, Any]]:
#     """Cached GitHub cache-file listing."""
#     return _fetch_github_cache_list_impl()


# # ============================================================================
# # SECTION 5: UI COMPONENTS (st.* allowed)
# # ============================================================================

# def _add_wms_layer(
#     m: folium.Map,
#     layers: str,
#     name: str,
#     show: bool,
#     opacity: float = 1.0,
# ) -> None:
#     """Helper ‚Äî add a Longdo WMS overlay to a Folium map."""
#     folium.WmsTileLayer(
#         url=LONGDO_WMS_URL,
#         layers=layers,
#         name=name,
#         fmt="image/png",
#         transparent=True,
#         version="1.1.1",
#         attr=f"{name} / Longdo Map",
#         show=show,
#         opacity=opacity,
#     ).add_to(m)


# def _render_sidebar_config_section() -> None:
#     """Config Import / Export expander."""
#     with st.expander("üíæ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Config (Export/Import)", expanded=False):
#         export_data = StateManager.export_config()
#         st.download_button(
#             "Download Config (.json)",
#             export_data,
#             "geo_cbd_config.json",
#             "application/json",
#             use_container_width=True,
#         )

#         uploaded_file = st.file_uploader(
#             "Upload .json", type=["json"], label_visibility="collapsed"
#         )
#         if uploaded_file and st.button("‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î", use_container_width=True):
#             try:
#                 data = json.load(uploaded_file)
#                 StateManager.import_config(data)
#                 st.toast("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", icon="üíæ")
#                 st.rerun()
#             except Exception as e:
#                 st.error(f"Error loading config: {e}")


# def _render_sidebar_marker_input() -> None:
#     """Manual coordinate input row."""
#     c1, c2 = st.columns([0.7, 0.3])
#     coords_input = c1.text_input(
#         "Coords",
#         placeholder="20.21, 100.40",
#         label_visibility="collapsed",
#         key="manual_coords",
#     )
#     if c2.button("‡πÄ‡∏û‡∏¥‡πà‡∏°", use_container_width=True):
#         try:
#             lat_str, lng_str = coords_input.strip().split(",")
#             StateManager.add_marker(float(lat_str), float(lng_str))
#             StateManager.clear_results(["isochrone", "intersection"])
#             st.rerun()
#         except Exception:
#             st.error("Format: Lat, Lng")


# def _render_sidebar_marker_list() -> List[Tuple[int, Dict[str, Any]]]:
#     """Render the marker list with toggle / delete controls. Returns active_list."""
#     markers = StateManager.get_markers()

#     # Delete last / Reset buttons
#     c1, c2 = st.columns(2)
#     if c1.button("‚ùå ‡∏•‡∏ö‡∏à‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", use_container_width=True) and markers:
#         StateManager.pop_last_marker()
#         StateManager.clear_results(["isochrone", "intersection"])
#         st.rerun()
#     if c2.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï", use_container_width=True):
#         StateManager.reset()
#         st.rerun()

#     active_list = StateManager.get_active_markers()
#     st.write(f"üìç Active Markers: **{len(active_list)}**")

#     if markers:
#         st.markdown("---")
#         for i, m in enumerate(markers):
#             col1, col2, col3 = st.columns([0.15, 0.70, 0.15])

#             prev_active = m.get("active", True)
#             is_active = col1.checkbox(
#                 " ",
#                 value=prev_active,
#                 key=f"active_chk_{i}",
#                 label_visibility="collapsed",
#             )

#             if is_active != prev_active:
#                 StateManager.set_marker_active(i, is_active)
#                 StateManager.clear_results(["isochrone", "intersection"])

#             if is_active:
#                 style = (
#                     f"color:{MARKER_COLORS[i % len(MARKER_COLORS)]}; font-weight:bold;"
#                 )
#             else:
#                 style = "color:gray; text-decoration:line-through;"
#             col2.markdown(
#                 f"<span style='{style}'>‚óè ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà {i+1}</span> "
#                 f"<span style='font-size:0.8em'>({m['lat']:.4f}, {m['lng']:.4f})</span>",
#                 unsafe_allow_html=True,
#             )

#             if col3.button("‚úï", key=f"del_btn_{i}"):
#                 StateManager.remove_marker(i)
#                 StateManager.clear_results(["isochrone", "intersection"])
#                 st.rerun()

#     # Refresh active list after possible mutations
#     return StateManager.get_active_markers()


# def _render_sidebar_network_panel() -> bool:
#     """
#     Render the Network Analysis expander (cache management + run button).

#     Returns ``True`` if the user clicked **Run Network Analysis**.
#     """
#     with st.expander("üï∏Ô∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢ (Network Analysis)", expanded=True):
#         st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏ñ‡∏ô‡∏ô (OSMnx)")

#         can_analyze = StateManager.get_isochrone_data() is not None
#         if can_analyze:
#             st.info("‚úÖ **Scope:** ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà Travel Areas ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", icon="üó∫Ô∏è")
#         else:
#             st.warning("‚ö†Ô∏è **Scope:** ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Isochrone ‡∏Å‡πà‡∏≠‡∏ô", icon="üõë")

#         # ---- Cache Management ----
#         cache_stats = get_cache_stats()
#         st.markdown("##### üíæ Cache Management")

#         if cache_stats["count"] > 0:
#             st.caption(
#                 f"üìä **{cache_stats['count']} ‡πÑ‡∏ü‡∏•‡πå** "
#                 f"({cache_stats['size_mb']:.1f} MB)"
#             )

#             if st.button(
#                 "üì§ Export Cache (.zip)",
#                 use_container_width=True,
#                 key="export_cache_btn",
#             ):
#                 zip_data = export_cache_as_zip()
#                 if zip_data:
#                     st.download_button(
#                         "‚¨á Download Ready",
#                         data=zip_data,
#                         file_name="osmnx_cache.zip",
#                         mime="application/zip",
#                         use_container_width=True,
#                     )

#             if st.button(
#                 "üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á Cache",
#                 use_container_width=True,
#                 type="secondary",
#             ):
#                 clear_disk_cache()
#                 st.toast("‡∏•‡πâ‡∏≤‡∏á Cache ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", icon="‚úÖ")
#                 st.rerun()
#         else:
#             st.caption("üìä **Cache ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤**")

#         # ---- GitHub Cache Selection ----
#         st.markdown("---")
#         st.markdown("##### üåê Cache ‡∏à‡∏≤‡∏Å GitHub")

#         github_caches = fetch_github_cache_list_cached()

#         if github_caches:
#             cache_options = ["-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Cache --"] + [
#                 f"{c['name']} ({c['size_kb']} KB)" for c in github_caches
#             ]
#             selected_idx = st.selectbox(
#                 "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Cache ‡∏à‡∏≤‡∏Å Repository",
#                 range(len(cache_options)),
#                 format_func=lambda i: cache_options[i],
#                 key="github_cache_select",
#                 label_visibility="collapsed",
#             )

#             if selected_idx > 0:
#                 selected_cache = github_caches[selected_idx - 1]
#                 if st.button(
#                     "üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î & ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤",
#                     use_container_width=True,
#                     type="primary",
#                 ):
#                     with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {selected_cache['name']}..."):
#                         zip_bytes, error = download_github_cache(
#                             selected_cache["download_url"]
#                         )
#                         if zip_bytes:
#                             imp_result = import_cache_from_zip(zip_bytes)
#                             if imp_result["success"]:
#                                 msg = (
#                                     f"‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ({imp_result['imported']} ‡πÉ‡∏´‡∏°‡πà, "
#                                     f"{imp_result['skipped']} ‡∏Ç‡πâ‡∏≤‡∏°)"
#                                 )
#                                 st.toast(msg, icon="‚úÖ")
#                                 st.rerun()
#                             else:
#                                 for err in imp_result["errors"]:
#                                     st.error(err)
#                         else:
#                             st.error(f"‚ùå {error}")
#         else:
#             st.caption("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö cache ‡πÉ‡∏ô GitHub ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")

#         # ---- Manual Cache Upload ----
#         st.markdown("---")
#         uploaded_cache = st.file_uploader(
#             "üì• Import Cache (.zip)",
#             type=["zip"],
#             key="cache_uploader",
#             label_visibility="visible",
#         )
#         if uploaded_cache:
#             if st.button(
#                 "‚úÖ ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤",
#                 use_container_width=True,
#                 type="secondary",
#             ):
#                 imp_result = import_cache_from_zip(uploaded_cache.read())
#                 if imp_result["success"]:
#                     msg = (
#                         f"‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ({imp_result['imported']} ‡πÉ‡∏´‡∏°‡πà, "
#                         f"{imp_result['skipped']} ‡∏Ç‡πâ‡∏≤‡∏°)"
#                     )
#                     st.toast(msg, icon="‚úÖ")
#                     st.rerun()
#                 else:
#                     for err in imp_result["errors"]:
#                         st.error(err)

#         st.markdown("---")
#         do_network: bool = st.button(
#             "üöÄ Run Network Analysis",
#             use_container_width=True,
#             disabled=not can_analyze,
#         )

#         # ---- Network results preview ----
#         net_data = StateManager.get_network_data()
#         if net_data and net_data.get("top_node"):
#             top = net_data["top_node"]
#             stats = net_data.get("stats", {})
#             st.markdown("---")
#             st.markdown("**üèÜ ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Integration Center)**")
#             st.caption(f"Score: {top['score']:.4f}")
#             if stats.get("used_approximation"):
#                 st.caption("‚ö° *‡πÉ‡∏ä‡πâ Approximation (‡∏Å‡∏£‡∏≤‡∏ü‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà)*")
#             st.code(f"{top['lat']:.5f}, {top['lon']:.5f}")

#             if st.button(
#                 "‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏•‡∏á‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
#                 use_container_width=True,
#                 type="secondary",
#             ):
#                 StateManager.add_marker(top["lat"], top["lon"])
#                 StateManager.clear_results(["isochrone", "intersection"])
#                 st.toast("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏î‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏´‡∏°‡πà", icon="‚úÖ")
#                 st.rerun()

#         st.markdown("##### Layer Controls")
#         st.checkbox("Show Roads (Betweenness)", key="show_betweenness")
#         st.caption("üî¥: ‡∏ó‡∏≤‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å (High Traffic Flow)")
#         st.checkbox("Show Nodes (Integration)", key="show_closeness")
#         st.caption("‚ö´: ‡∏à‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏á‡πà‡∏≤‡∏¢ (Central Hub)")

#     return do_network


# def _render_sidebar_map_settings() -> None:
#     """Map & Layer settings expander."""
#     with st.expander("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà & Layers", expanded=True):
#         st.selectbox("‡∏™‡πÑ‡∏ï‡∏•‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà", list(MAP_STYLES.keys()), key="map_style_name")
#         st.checkbox("üö¶ ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£ (Google Traffic)", key="show_traffic")
#         st.checkbox("üë• ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£", key="show_population")

#         c1, c2 = st.columns([0.65, 0.35])
#         c1.checkbox("üèôÔ∏è ‡∏ú‡∏±‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏£‡∏ß‡∏°", key="show_cityplan")
#         if st.session_state.show_cityplan:
#             c2.slider(
#                 "Op.", 0.2, 1.0, key="cityplan_opacity", label_visibility="collapsed"
#             )

#         st.checkbox("üìú ‡∏£‡∏π‡∏õ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô", key="show_dol")

#         st.markdown("##### üöó ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á (Isochrone)")
#         st.selectbox(
#             "‡πÇ‡∏´‡∏°‡∏î",
#             list(TRAVEL_MODE_NAMES.keys()),
#             format_func=TRAVEL_MODE_NAMES.get,
#             key="travel_mode",
#         )
#         st.multiselect("‡πÄ‡∏ß‡∏•‡∏≤ (‡∏ô‡∏≤‡∏ó‡∏µ)", TIME_OPTIONS, key="time_intervals")


# def render_sidebar() -> Tuple[bool, bool, List[Tuple[int, Dict[str, Any]]]]:
#     """
#     Orchestrate the full sidebar.

#     Returns:
#         ``(do_calculate, do_network, active_markers_list)``
#     """
#     with st.sidebar:
#         st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

#         _render_sidebar_config_section()
#         st.markdown("---")
#         _render_sidebar_marker_input()

#         st.text_input("Geoapify API Key", key="api_key", type="password")

#         active_list = _render_sidebar_marker_list()
#         st.markdown("---")

#         do_network = _render_sidebar_network_panel()
#         st.markdown("---")

#         _render_sidebar_map_settings()

#         do_calc: bool = st.button(
#             "üß© ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏´‡∏≤ Isochrone CBD",
#             type="primary",
#             use_container_width=True,
#         )

#     return do_calc, do_network, active_list


# def render_map() -> Optional[Dict[str, Any]]:
#     """Build and display the Folium map. Returns the ``st_folium`` output dict."""
#     style_conf = MAP_STYLES[StateManager.get_map_style_name()]
#     markers = StateManager.get_markers()
#     center = (
#         [markers[-1]["lat"], markers[-1]["lng"]]
#         if markers
#         else [DEFAULT_CONFIG["LAT"], DEFAULT_CONFIG["LON"]]
#     )

#     m = folium.Map(
#         location=center,
#         zoom_start=14,
#         tiles=style_conf["tiles"],
#         attr=style_conf["attr"],
#     )

#     # ---- Traffic overlay ----
#     if st.session_state.show_traffic:
#         folium.TileLayer(
#             tiles="https://mt1.google.com/vt?lyrs=h,traffic&x={x}&y={y}&z={z}",
#             attr="Google Traffic",
#             name="Google Traffic",
#             overlay=True,
#         ).add_to(m)

#     # ---- Network Analysis Layers ----
#     net_data = StateManager.get_network_data()
#     if net_data and "error" not in net_data:
#         # Edges (Betweenness)
#         if st.session_state.show_betweenness and net_data.get("edges"):
#             folium.GeoJson(
#                 net_data["edges"],
#                 name="Road Betweenness",
#                 style_function=lambda x: {
#                     "color": x["properties"]["color"],
#                     "weight": x["properties"]["stroke_weight"],
#                     "opacity": 0.8,
#                 },
#                 tooltip=folium.GeoJsonTooltip(
#                     fields=["betweenness"],
#                     aliases=["Betweenness Score:"],
#                     localize=True,
#                 ),
#             ).add_to(m)

#         # Nodes (Closeness)
#         if st.session_state.show_closeness and net_data.get("nodes"):
#             folium.GeoJson(
#                 net_data["nodes"],
#                 name="Node Integration",
#                 marker=folium.CircleMarker(),
#                 style_function=lambda x: {
#                     "fillColor": x["properties"]["color"],
#                     "color": "#000000",
#                     "weight": 1,
#                     "radius": x["properties"]["radius"],
#                     "fillOpacity": 0.9,
#                 },
#                 tooltip=folium.GeoJsonTooltip(
#                     fields=["closeness"],
#                     aliases=["Integration Score:"],
#                     localize=True,
#                 ),
#             ).add_to(m)

#         # Top Node marker
#         if net_data.get("top_node"):
#             top = net_data["top_node"]
#             folium.Marker(
#                 [top["lat"], top["lon"]],
#                 popup=f"üèÜ Center (Score: {top['score']:.4f})",
#                 icon=folium.Icon(color="orange", icon="star", prefix="fa"),
#                 tooltip="‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
#             ).add_to(m)

#     # ---- Isochrone polygons ----
#     iso_data = StateManager.get_isochrone_data()
#     if iso_data:
#         clrs = StateManager.get_colors()
#         folium.GeoJson(
#             iso_data,
#             name="Travel Areas",
#             style_function=lambda x: {
#                 "fillColor": get_fill_color(
#                     x["properties"]["travel_time_minutes"], clrs
#                 ),
#                 "color": get_border_color(x["properties"]["original_index"]),
#                 "weight": 1,
#                 "fillOpacity": 0.2,
#             },
#         ).add_to(m)

#     # ---- CBD intersection ----
#     inter_data = StateManager.get_intersection_data()
#     if inter_data:
#         folium.GeoJson(
#             inter_data,
#             name="CBD Zone",
#             style_function=lambda _x: {
#                 "fillColor": "#FFD700",
#                 "color": "#FF8C00",
#                 "weight": 3,
#                 "fillOpacity": 0.6,
#                 "dashArray": "5, 5",
#             },
#         ).add_to(m)

#     # ---- WMS Layers ----
#     _add_wms_layer(
#         m, "thailand_population", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£",
#         st.session_state.show_population,
#     )
#     _add_wms_layer(
#         m, "cityplan_dpt", "‡∏ú‡∏±‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏£‡∏ß‡∏°",
#         st.session_state.show_cityplan,
#         opacity=st.session_state.cityplan_opacity,
#     )
#     _add_wms_layer(
#         m, "dol", "‡∏£‡∏π‡∏õ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô", st.session_state.show_dol
#     )

#     # ---- Markers ----
#     for i, marker in enumerate(markers):
#         active = marker.get("active", True)
#         folium.Marker(
#             [marker["lat"], marker["lng"]],
#             popup=f"‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà {i+1}",
#             icon=folium.Icon(
#                 color=MARKER_COLORS[i % len(MARKER_COLORS)] if active else "gray",
#                 icon="map-marker" if active else "ban",
#                 prefix="fa",
#             ),
#         ).add_to(m)

#     folium.LayerControl().add_to(m)
#     return st_folium(m, height=900, use_container_width=True, key="main_map")


# # ============================================================================
# # SECTION 6: BUSINESS LOGIC ORCHESTRATORS
# # ============================================================================

# def perform_calculation(
#     active_list: List[Tuple[int, Dict[str, Any]]]
# ) -> None:
#     """Fetch isochrones for all active markers, compute CBD intersection."""
#     # ---- Validation ----
#     api_key = StateManager.get_api_key()
#     if not api_key:
#         st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key")
#         return
#     if not active_list:
#         st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏∏‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏à‡∏∏‡∏î")
#         return
#     time_intervals = StateManager.get_time_intervals()
#     if not time_intervals:
#         st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
#         return

#     travel_mode = StateManager.get_travel_mode()

#     with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Isochrone..."):
#         all_features: List[Dict[str, Any]] = []
#         ranges_str = ",".join(str(t * 60) for t in sorted(time_intervals))
#         errors: List[str] = []

#         for act_idx, (orig_idx, marker) in enumerate(active_list):
#             features, error_msg = fetch_api_data_cached(
#                 api_key, travel_mode, ranges_str, marker["lat"], marker["lng"]
#             )

#             if features is None:
#                 errors.append(f"‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà {orig_idx + 1}: {error_msg}")
#                 continue

#             for f in features:
#                 f["properties"].update(
#                     {
#                         "travel_time_minutes": f["properties"].get("value", 0) / 60,
#                         "original_index": orig_idx,
#                         "active_index": act_idx,
#                     }
#                 )
#                 all_features.append(f)

#         # Display collected errors
#         for error in errors:
#             st.error(error)
#         if not all_features:
#             return  # All requests failed

#         # Store isochrone results
#         StateManager.set_isochrone_data(
#             {"type": "FeatureCollection", "features": all_features}
#         )

#         # Calculate CBD intersection
#         cbd_geom = calculate_intersection(all_features, len(active_list))
#         if cbd_geom:
#             StateManager.set_intersection_data(
#                 {
#                     "type": "FeatureCollection",
#                     "features": [
#                         {
#                             "type": "Feature",
#                             "geometry": cbd_geom,
#                             "properties": {"type": "cbd"},
#                         }
#                     ],
#                 }
#             )
#             st.toast("‚úÖ ‡∏û‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà CBD!", icon="üéØ")
#         else:
#             StateManager.set_intersection_data(None)
#             st.toast("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô", icon="‚ö†Ô∏è")


# def _run_network_analysis_with_progress(
#     polygon_wkt_str: str, network_type: str
# ) -> Dict[str, Any]:
#     """
#     Thin UI wrapper that shows progress while the **cached** pure function runs.
#     """
#     progress_bar = st.progress(0)
#     status_container = st.empty()

#     try:
#         # Stage 1: Prepare
#         status_container.info("üîç **Stage 1/3:** ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà...")
#         progress_bar.progress(0.05)

#         # Stage 2: Check cache
#         cache_key = get_cache_key(polygon_wkt_str, network_type)
#         is_cached = load_graph_from_cache(cache_key) is not None

#         if is_cached:
#             status_container.success("‚úÖ **‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Cache!** ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î...")
#         else:
#             status_container.warning(
#                 "‚è≥ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å...** (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 5-10 ‡∏ô‡∏≤‡∏ó‡∏µ)"
#             )
#         progress_bar.progress(0.10)

#         # Stage 3: Compute
#         status_container.info("üõ£Ô∏è **Stage 2/3:** ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô...")
#         progress_bar.progress(0.30)

#         result = compute_centrality_cached(polygon_wkt_str, network_type)

#         progress_bar.progress(0.90)

#         # Stage 4: Report
#         if "error" in result:
#             status_container.error(f"‚ùå {result['error']}")
#         else:
#             stats = result.get("stats", {})
#             status_container.success(
#                 f"‚úÖ **‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!** ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {stats.get('nodes_count', 0):,} ‡πÇ‡∏´‡∏ô‡∏î "
#                 f"‡πÅ‡∏•‡∏∞ {stats.get('edges_count', 0):,} ‡∏ñ‡∏ô‡∏ô"
#             )
#         progress_bar.progress(1.0)

#     finally:
#         progress_bar.empty()
#         status_container.empty()

#     return result


# def perform_network_analysis() -> None:
#     """Orchestrate the full network analysis pipeline."""
#     iso_data = StateManager.get_isochrone_data()
#     if not iso_data:
#         st.error("‚ùå No Isochrone data found. Please calculate isochrones first.")
#         return

#     with st.spinner(
#         "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô (OSMnx)... ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"
#     ):
#         try:
#             # 1. Union all travel polygons
#             feats_json = json.dumps(iso_data.get("features", []))
#             combined_wkt = union_all_polygons_cached(feats_json)

#             if not combined_wkt:
#                 st.error("‚ùå No polygons to analyze.")
#                 return

#             # 2. Run analysis with progress UI
#             net_type = TRAVEL_MODE_TO_NETWORK_TYPE.get(
#                 StateManager.get_travel_mode(), "drive"
#             )
#             result = _run_network_analysis_with_progress(combined_wkt, net_type)

#             if "error" in result:
#                 st.error(f"‚ùå Network Analysis Failed: {result['error']}")
#                 st.info(
#                     "üí° **Tips:**\n"
#                     "- Try a larger area\n"
#                     "- Check if the location has road data in OpenStreetMap\n"
#                     "- Verify internet connection"
#                 )
#             else:
#                 StateManager.set_network_data(result)
#                 score_info = (
#                     f"Score: {result['top_node']['score']:.4f}"
#                     if result.get("top_node")
#                     else ""
#                 )
#                 st.toast(f"‚úÖ Analysis Completed! {score_info}", icon="üèÜ")

#         except Exception as e:
#             st.error(f"‚ùå Processing Error: {e}")
#             st.info(
#                 "üí° If the error persists, try a different location "
#                 "or smaller time intervals."
#             )


# def handle_map_click(map_output: Optional[Dict[str, Any]]) -> None:
#     """Process a map click event ‚Äî add marker if debounce passes."""
#     if not map_output:
#         return
#     clicked = map_output.get("last_clicked")
#     if not clicked:
#         return

#     last = StateManager.get_last_click()
#     if should_add_marker(clicked["lat"], clicked["lng"], last):
#         StateManager.add_marker(clicked["lat"], clicked["lng"])
#         StateManager.record_click(clicked["lat"], clicked["lng"])
#         StateManager.clear_results(["isochrone", "intersection"])
#         st.rerun()


# # ============================================================================
# # SECTION 7: MAIN EXECUTION
# # ============================================================================

# def main() -> None:
#     st.set_page_config(**PAGE_CONFIG)

#     # Inject minimal CSS to fix spacing
#     st.markdown(
#         "<style>"
#         ".block-container { padding-top: 2rem; padding-bottom: 0rem; } "
#         "h1 { margin-bottom: 0px; } "
#         "div[data-testid=\"stHorizontalBlock\"] button "
#         "{ padding: 0rem 0.5rem; }"
#         "</style>",
#         unsafe_allow_html=True,
#     )

#     # 1. Initialize State
#     StateManager.initialize()

#     # 2. Render Sidebar ‚Üí capture user intents
#     do_calc, do_net, active_list = render_sidebar()

#     # 3. Execute Business Logic (based on user intents)
#     if do_calc:
#         perform_calculation(active_list)

#     if do_net:
#         perform_network_analysis()

#     # 4. Render Map
#     map_output = render_map()

#     # 5. Handle Map Click ‚Üí mutate state & rerun
#     handle_map_click(map_output)


# if __name__ == "__main__":
#     main()
